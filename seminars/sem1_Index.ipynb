{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 1 Индекс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "### работа с файлами и папками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "filepath = os.path.join(curr_dir, 'test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path  \n",
    "путь до файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Женя\\GitHub\\Программирование\\infosearch\\seminars\\test.txt\n",
      "test.txt\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# возвращает полный путь до папки/файла по имени файла / папки\n",
    "print(os.path.abspath(filepath))\n",
    "\n",
    "\n",
    "# возвращает имя файла / папки по полному ти до него\n",
    "print(os.path.basename(filepath))\n",
    "\n",
    "\n",
    "# проверить существование директории - True / False\n",
    "print(os.path.exists(curr_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.listdir  \n",
    "возвращает список файлов в данной директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'sem1_Index.ipynb']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(curr_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При обходе файлов не забывайте исключать системные директории, такие как .DS_Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.walk\n",
    "root - начальная директория  \n",
    "dirs - список поддиректорий (папок)   \n",
    "files - список файлов в этих поддиректориях  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Женя\\GitHub\\Программирование\\infosearch\\seminars\\sem1_Index.ipynb\n",
      "C:\\Users\\User\\Женя\\GitHub\\Программирование\\infosearch\\seminars\\.ipynb_checkpoints\\sem1_Index-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(curr_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __os.walk__ возвращает генератор, это значит, что получить его элементы можно только проитерировавшись по нему  \n",
    "но его легко можно превратить в list и увидеть все его значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C:\\\\Users\\\\User\\\\Женя\\\\GitHub\\\\Программирование\\\\infosearch\\\\seminars',\n",
       "  ['.ipynb_checkpoints'],\n",
       "  ['sem1_Index.ipynb']),\n",
       " ('C:\\\\Users\\\\User\\\\Женя\\\\GitHub\\\\Программирование\\\\infosearch\\\\seminars\\\\.ipynb_checkpoints',\n",
       "  [],\n",
       "  ['sem1_Index-checkpoint.ipynb'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(os.walk(curr_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### чтение файла "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bee46aff2113>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# одним массивом\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fpath' is not defined"
     ]
    }
   ],
   "source": [
    "filepath = 'test.txt'\n",
    "\n",
    "\n",
    "# одним массивом  \n",
    "with open(fpath, 'r') as f:  \n",
    "    text = f.read() \n",
    "\n",
    "    \n",
    "#по строкам, в конце каждой строки \\n  \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.readlines() \n",
    "\n",
    "    \n",
    "#по строкам, без \\n   \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминание про enumerate:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "``` for i, element in enumerate(your_list): ...  ```    \n",
    "Иногда для получения элемента делают так -  ``` your_list[i] ```, не надо так"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример реализации обратного индекса через CountVectorizer. Пользуйтесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[1 1 1 0]\n",
      " [0 1 1 0]\n",
      " [2 1 0 0]\n",
      " [0 0 0 1]] \n",
      "\n",
      "get_feature_names: ['слово1', 'слово2', 'слово3', 'слово4'] \n",
      "\n",
      "vocabulary_.get: 0\n",
      "vocabulary_.get: 3 \n",
      "\n",
      "transform: [[1 0 0 2]]\n",
      "transform: [[0 0 0 0]] \n",
      "\n",
      "matrix_freq: [3 3 2 1] \n",
      "\n",
      "final_matrix: [['слово1' 'слово2' 'слово3' 'слово4']\n",
      " ['3' '3' '2' '1']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    " \n",
    "# инициализируем\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "\n",
    "# составляем корпус документов\n",
    "corpus = [\n",
    "  'слово1 слово2 слово3',\n",
    "  'слово2 слово3',\n",
    "  'слово1 слово2 слово1',\n",
    "  'слово4'\n",
    "]\n",
    "\n",
    "# считаем\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "# получится следующая структура:\n",
    "#        | слово1 | слово2 | слово3 | слово4\n",
    "# текст1 |   1    |    1   |   1    |   0\n",
    "# текст2 |   0    |    1   |   1    |   0\n",
    "# текст3 |   2    |    1   |   0    |   0\n",
    "# текст4 |   0    |    0   |   0    |   1\n",
    "\n",
    "# показать матрицу\n",
    "print('X:\\n', X.toarray(), '\\n')\n",
    "\n",
    " \n",
    "# чтобы получить сгенерированный словарь, из приведенной структуры CountVectorizer\n",
    "# порядок совпадает с матрицей\n",
    "print('get_feature_names:', vectorizer.get_feature_names(), '\\n')  # ['слово1', 'слово2', 'слово3', 'слово4']\n",
    " \n",
    "    \n",
    "# чтобы узнать индекс токена в словаре\n",
    "print('vocabulary_.get:', vectorizer.vocabulary_.get('слово1')) # вернет 0\n",
    "print('vocabulary_.get:', vectorizer.vocabulary_.get('слово4'), '\\n') # вернет 3\n",
    "\n",
    " \n",
    "# теперь можно быстро подсчитать вектор для нового документа\n",
    "print('transform:', vectorizer.transform(['слово1 слово4 слово4']).toarray())  # результат [[1 0 0 2]]\n",
    "print('transform:', vectorizer.transform(['слово5']).toarray(), '\\n')\n",
    "\n",
    " \n",
    "# чтобы узнать количественное вхождение каждого слова:\n",
    "matrix_freq = np.asarray(X.sum(axis=0)).ravel()\n",
    "print('matrix_freq:', matrix_freq, '\\n')  # результат [3 3 2 1] \n",
    "\n",
    "final_matrix = np.array([np.array(vectorizer.get_feature_names()), matrix_freq])\n",
    "print('final_matrix:', final_matrix, '\\n')  # результат [['слово1' 'слово2' 'слово3' 'слово4'], ['3' '3' '2' '1']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['слово1 слово4 слово4']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Индекс \n",
    "\n",
    "Сам по себе индекс - это просто формат хранения данных, он не может осуществлять поиск. Для этого необходимо добавить к нему определенную метрику. Это может быть что-то простое типа булева поиска, а может быть что-то более специфическое или кастомное под задачу.\n",
    "\n",
    "Давайте посмотрим, что полезного можно вытащить из самого индекса.    \n",
    "Например, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе - так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. как эти документы кластеризуются по N тематикам согласно словам, которые в них упоминаются "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Задача__: \n",
    "\n",
    "**Data:** Коллекция субтитров сезонов Друзей. Одна серия - один документ.\n",
    "\n",
    "**To do:** \n",
    "\n",
    "**1 Создайте обратный индекс этой базы, используя CountVectorizer. \n",
    "То, что вы получите, называется матрица Term-Document.**\n",
    "\n",
    "Компоненты вашей реализации:\n",
    "    - Функция препроцессинга данных. Включите туда лемматизацию, приведение к одному регистру, удаление пунктуации и стоп-слов.\n",
    "    - Функция индексирования данных. На выходе создает обратный индекс, он же матрица Term-Document.\n",
    "\n",
    "**2 С помощью обратного индекса посчитайте:** \n",
    "\n",
    "\n",
    "a) какое слово является самым частотным\n",
    "\n",
    "b) какое самым редким\n",
    "\n",
    "c) какой набор слов есть во всех документах коллекции\n",
    "\n",
    "d) кто из главных героев статистически самый популярный (упонимается чаще всего)? Имена героев:\n",
    "- Моника\n",
    "- Рэйчел \n",
    "- Чендлер\n",
    "- Фиби\n",
    "- Росс\n",
    "- Джоуи, Джои\n",
    "\n",
    "**На что направлены эти задачи:** \n",
    "1. Навык построения обратного индекса\n",
    "2. Навык работы с этим индексом, а именно как с помощью numpy или pandas достать нужную информацию из матрицы данных\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/4wmU7R8JL-k_RA?w=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('russian')\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('ru_core_news_lg', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### _check : в коллекции должно быть 165 файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for root, dirs, files in os.walk('friends-data'):\n",
    "    if '.ipynb_checkpoints' not in root:\n",
    "        for name in files:\n",
    "            filepath = os.path.join(root, name)\n",
    "            with open(filepath, encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                corpus.append(text)\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check passed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmata = [token.lemma_ for token in doc if token.is_alpha if token.text not in STOPWORDS if token.pos_ != 'PRON']\n",
    "    lemmata = [lemma for lemma in lemmata if lemma not in STOPWORDS]\n",
    "    \n",
    "    return ' '.join(lemmata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "corpus = [preprocess_text(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "index = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'этот' in STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'это'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[index.sum(axis=0).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, ..., 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.sum(axis=0)[index.sum(axis=0) == index.sum(axis=0).min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(index.sum(axis=0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 0],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1, 2, 0], [0, 0, 0], [1, 1, 1]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [0, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, [0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
